#!/usr/bin/env python

from Bio import Entrez
import pandas as pd
from urllib.error import HTTPError
import argparse as ap
import logging
import ntpath
import os

def parseft(handle):
    map = {}
    filecontent = {}

    while True:
        # read first line of record
        line = handle.readline()
        if line:
            # retrieving the accession number without the version at the end
            acc = line.split('|')[1].split('.')[0]

            # initialize filecontent entry and line counter for genesymbol
            filecontent[acc], symboline = '', 0

            # read lines until next entry
            while not line == '\n':
                filecontent[acc] += line
                if symboline == 2:
                    map[acc] = line.rstrip().split('\t')[-1]

                line = handle.readline()
                symboline += 1
        else:
            break

    return map, filecontent


def retrieve_annoations(id_list, bulk = 5000, db = 'nucleotide'):
    map = {}
    filecontent = {}
    #iterating over id_list in bulks due to an upper limit of 10000 ids per request
    for i in range(0, len(id_list), bulk):
        bulklist = id_list[i: i + bulk] if i + bulk < len(id_list) else id_list[i:]

        retrieved = False
        while not retrieved:
            try:
                handle = Entrez.efetch(db = db, id=','.join(bulklist), rettype = 'ft', retmode = 'text')
                retrieved = True
            except HTTPError:
                logging.info('connection lost, retrying')
                continue

        # updating retdicts
        for d, tmpd in zip([map, filecontent], parseft(handle)):
            d.update(tmpd)

        logging.info('Retrieved %d annotations of %d genes' % (len(map), len(id_list)))

    return map, filecontent

if __name__ == '__main__':
    logging.basicConfig(format='%(asctime)s - %(message)s', level=logging.INFO)
    parser = ap.ArgumentParser()
    parser.add_argument('-a', '--annotation', required = True,
                        help = 'tab-separated annotation file containing EntrezIds for all entries as generated by peakannotation.R')
    parser.add_argument('--blocksize', default = 5000, type = int,
                        help = 'number of EntrezIds to fetch from the database at once (larger values might increase runtime)')
    parser.add_argument('--email', required = True,
                        help = 'email address to use for connecting to the Entrez database')
    parser.add_argument('-m', '--mapping', default = None,
                        help = 'name of the file containing the mapping from EntrezID to gene symbol (is created if not already existing)')
    parser.add_argument('-o', '--outputFile', required = True,
                        help = 'name of the file to write results to')
    args = parser.parse_args()

    Entrez.email = args.email

    logging.info('reading annotated peaks from %s' % args.annotation)
    anno = pd.read_csv(args.annotation, sep = '\t')

    logging.info('looking for featuretable %s' % args.mapping)
    if not os.path.exists(args.mapping):
        logging.info('generating %s' % args.mapping)
        annotations, filecontents = {}, {}

    else:
        logging.info('reading in featuretable from %s' % args.mapping)
        with open(args.mapping, 'r') as ft:
            annotations, filecontents = parseft(ft)

    # only retrieve those that are not already in the feature table
    id_list = []
    for id in anno.transcriptId.unique():
        if not annotations.get(id):
            id_list.append(id)
        else:
            continue

    logging.info('%d unique Entrez IDs to map' % len(anno.transcriptId.unique()))
    logging.info('%d are already in %s' % (len(anno.transcriptId.unique()) - len(id_list), args.mapping))

    for d, tmpd in zip([annotations, filecontents], retrieve_annoations(id_list, bulk = args.blocksize)):
        d.update(tmpd)

    logging.info('retrieved %d unique ID maps in total' % len(annotations))

    logging.info('merging annotation and retrieved ID maps and writing file %s' %
                    args.annotation.replace('tsv', 'mapped.tsv'))

    mapframe = pd.DataFrame().from_dict(annotations, orient='index').reset_index()
    mapframe.columns = ['transcriptId', 'genesymbol']

    anno = anno.merge(mapframe, how='left', on='transcriptId')

    # converting back to 0-based half open as ChipSeeker converts to 1-based fully closed
    anno.loc[:, 'start'] = anno['start'] - 1
    anno.to_csv(args.outputFile), sep='\t', index=False)
